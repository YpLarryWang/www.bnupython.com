---
prev: ./ex3_beginners_village_part3
---

# 爬虫作业：用户评论挖掘

## 作业说明

- 选择一个包含用户评论的网站，如B站、QQ音乐、好大夫在线等
- 爬取不同类别的评论数据，至少5类，每类至少1000条
- 对不同类别的评论数据进行关键词抽取，并以词云呈现

## 提交文件

- Python文件 : 爬虫、解析、绘图等，确保可运行
- TXT文件 : 每个榜单获取的评论 : comments_(类型名).txt 每条评论占一行
- PPT文件 : 每个榜一张词云图

## 提交时间

- 5月3日晚上12点前发送到邮箱202221090021@mail.bnu.edu.cn
- 注 : 作业压缩包命名为“【姓名】爬虫作业”

## 温馨提示

1. 如果你希望爬取的是比较大的网站且爬取数据量较大，可以在Github或Google上搜索相关项目或参考代码；
   - 如果Github或Google上没有现成的代码可供参考，可以使用官方提供的API接口来获取数据。这种方法可以避免被网站封锁或限制请求频率的问题。在使用API时，需要仔细阅读文档，理解API的参数和返回值，并确保自己的请求方式和频率符合网站的要求。
2. 如果你希望爬取的网站比较小众，或者上述方法都未能解决问题，那么可能需要自己编写爬虫程序。在编写爬虫时，你需要制定一个良好的爬虫策略，以确保你的程序不会被网站封锁或出现其他错误。这里我们给出一个通用策略，简记为`sleep & try & save & check`：
   - 使用`sleep`。在进行请求之间间隔一段时间，以避免频繁的请求被网站检测到并被阻止；
   - 使用`try / except`语句处理异常。在进行爬虫过程中，可能会遇到各种异常情况，如网络错误、页面解析错误和数据格式错误等。在编写爬虫程序时，需要考虑这些异常情况，并编写相应的异常处理代码。
   - `save`表示在请求数据时将其保存到本地文件或数据库中，以避免意外中断导致数据丢失；
   - `check`表示在请求数据后检查数据的有效性，以确保数据的准确性。
3. 将爬取到的评论数据生成词云可以使数据更加直观。你可以使用Python的`wordcloud`库来生成词云。在生成词云时，可以根据需要自定义字体、颜色和背景等设置。
